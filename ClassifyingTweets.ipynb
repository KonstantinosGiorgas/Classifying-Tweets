{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignement_3.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "2DTirTmv7-J1",
        "2GvHTyqU9L-6"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kU4XY5cdN4jZ"
      },
      "source": [
        "# **Classifying MEP tweets based on Political Party**\n",
        "## Konstantinos Giorgas\n",
        "### *Athens, 12/03/2020*\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XYJDMcTuWvA4"
      },
      "source": [
        "## Loading Libraries and Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i821CqFJooL9"
      },
      "source": [
        "### Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IIBrKSkYxkOT",
        "outputId": "7713a5d3-c21f-4178-a365-33cdca129a38",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "import tweepy\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from html import unescape\n",
        "from sklearn import model_selection, preprocessing, tree, naive_bayes, metrics, svm, decomposition\n",
        "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier, ExtraTreesClassifier, AdaBoostClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "import xgboost as xgb\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer, TfidfTransformer\n",
        "from sklearn.model_selection import cross_val_score, KFold, GridSearchCV\n",
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from scipy.stats import sem\n",
        "from sklearn import svm\n",
        "import nltk\n",
        "from nltk import ngrams\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize \n",
        "from nltk.probability import FreqDist\n",
        "from collections import Counter\n",
        "import spacy\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "import math"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
            "  \"(https://pypi.org/project/six/).\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sl94GGu1pKWD"
      },
      "source": [
        "### Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "si3KvoJhpJ2s"
      },
      "source": [
        "def my_preprocessor(document):\n",
        "  #deletes all links from corpus, replaces n't with not keeps only letters and turns all letters\n",
        "  #to lowercase after translating any html character\n",
        "  step1 = re.sub(r'http\\S+', '', document)\n",
        "  step2 = step1.replace(\"won't\",\"will not\").replace(\"n't\",\" not\").replace(\"!\",\" exlmrk\").replace(\"?\",\" qsnmrk\")\n",
        "  step3 = re.sub(r'[^a-zA-Z_@&]+', ' ', unescape(step2.lower()))\n",
        "  step4 = ' '.join([w for w in step3.split() if len(w)>1])\n",
        "  return step4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1PIe6C84pSRF"
      },
      "source": [
        "def my_tokenizer(doc):\n",
        "  #keeps only words that consist of more than 2 letters and exist in a predifined vocabulary\n",
        "  tokens = doc.split()\n",
        "  return(tokens)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wtMGMGI_skCV"
      },
      "source": [
        "def getWordFreq(corpus):\n",
        "  #counts and prints the frequency of each unique word in a given corpus\n",
        "    result = {}\n",
        "    for sentence in corpus:\n",
        "        for word in sentence.split():\n",
        "            if word in result:\n",
        "                result[word] += 1\n",
        "            else:\n",
        "                result[word] = 1\n",
        "    result = sorted(result.items(), key=lambda x: x[1], reverse=True)   \n",
        "    return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "73Qgb1bLB-eC"
      },
      "source": [
        "## Data Preprocessing\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H9OFRTTJXMiG"
      },
      "source": [
        "### Data Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_smN6RXwzpT",
        "outputId": "e6b7f0e7-9b59-4e84-8927-4a577b2edd00",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "# This chunk of code is nessesary only if run in Google Colab.\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "%cd '/gdrive/My Drive/louridas/assignment_3'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /gdrive\n",
            "/gdrive/My Drive/louridas/assignment_3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eOuwXVt-xhfq"
      },
      "source": [
        "tweets = pd.read_csv('retweets.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xTiY8M5GxwIa"
      },
      "source": [
        "tweets = tweets.loc[tweets.lang == 'en']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vs_4Mj4VJHZ7",
        "outputId": "e5bb9896-c585-4a15-e5d0-3f3b459cce37",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tweets.shape[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13796"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S7wh6i9YUp-a"
      },
      "source": [
        "In this step I remove all the ids that belong to a group having frequency of less than 50 tweets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XkSxwMKv9A7d"
      },
      "source": [
        "frequency_counts = tweets.origMepGroupShort.value_counts()\n",
        "to_remove = frequency_counts[frequency_counts <= 50].index\n",
        "tweets.replace(to_remove, np.nan, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EvQgBgtyVKm1"
      },
      "source": [
        "In this step I initiate all the requested credentials for a succesfull tweeter API call."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7jadFhraykH4"
      },
      "source": [
        "#Twitter API Authentication\n",
        "consumer_key = 'consumer_key'\n",
        "consumer_secret = 'consumer_secret'\n",
        "access_token = 'access_token'\n",
        "access_token_secret = 'access_token_secret'\n",
        "\n",
        "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
        "auth.set_access_token(access_token, access_token_secret)\n",
        "\n",
        "api = tweepy.API(auth)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZZrkdqbCViJu"
      },
      "source": [
        "In order not to violate the batch limit of tweeter API and to make the process of downloading tweets as fast as possible I downloaded the tweets based on the given tweet id in batches of 99 tweets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1HEbVQDS3lrP"
      },
      "source": [
        "start, stop = 0, 0\n",
        "tweet_txt = []\n",
        "limit = tweets.shape[0] - 1\n",
        "tweet_ids = tweets.origTweetId\n",
        "\n",
        "while stop <= limit:\n",
        "  start = stop\n",
        "  stop = start + 100\n",
        "  if stop > limit: stop = limit\n",
        "  batch_tweets = api.statuses_lookup(id_= [x for x in tweet_ids[start:stop]])\n",
        "  for tweet in batch_tweets:\n",
        "      tweet_txt.append([tweet.id, tweet.text])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-MAl_6f-OPMP",
        "outputId": "1824a52d-47a7-495f-c8c8-49195819d827",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(tweet_txt)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10193"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zYh_JGrQWJ3h"
      },
      "source": [
        "After removing all duplicates and dropping all `NA` values I was able to create my dataset containing of unique tweet ids and their corresponding MEP group."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y1xDEw5vjROX"
      },
      "source": [
        "tweet_txt = pd.DataFrame(tweet_txt, columns = ['origTweetId', 'text'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9lr-Q0I9jrDL"
      },
      "source": [
        "tweet_txt = pd.merge(tweet_txt, tweets[['origTweetId', 'origMepGroupShort']],\n",
        "                     how = 'left', on = 'origTweetId')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VWSud9ah797-"
      },
      "source": [
        "tweet_txt = tweet_txt.drop_duplicates()\n",
        "tweet_txt = tweet_txt.dropna()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QGAg946YCZZm"
      },
      "source": [
        "traindata = pd.DataFrame()\n",
        "traindata['text'] = tweet_txt.text\n",
        "traindata['label'] = tweet_txt.origMepGroupShort"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u9JG2PyWC6W9"
      },
      "source": [
        "### Data Exploration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4D4J2nI5FPnI"
      },
      "source": [
        "I do not want any of the test set characteristics to bleed into my training dataset so at first I split the data set to train and test set as follows: 75% train data and 25% test data. I will also create a deep copy of each set since I indend to train a neural network that will require a different dataset format than traditional machine learnig practices. I will use `random_state` to make sure my results are consistent."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0eZ2Z1SFEss"
      },
      "source": [
        "train_X, valid_X, train_Y, valid_Y = model_selection.train_test_split(traindata.text, traindata.label, random_state = 1)\n",
        "freq = train_Y.value_counts().reset_index()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RDKVGe62z1MX"
      },
      "source": [
        "train_x = [x for x in train_X]\n",
        "train_y = [y for y in train_Y]\n",
        "valid_x = [x for x in valid_X]\n",
        "valid_y = [y for y in valid_Y]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ihKq3ULMdw0e"
      },
      "source": [
        " As we can see from the distribution of the groups in our test data there is great imbalance between them"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6pqc5M5IaQ7d",
        "outputId": "db11fa99-8df9-4c7a-9afb-5ff979cbb3b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        }
      },
      "source": [
        "plt.bar(freq['index'], freq.label)\n",
        "plt.title('Number of tweets per group')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEICAYAAACzliQjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gBkmzthJeG5G"
      },
      "source": [
        "As expected stop words appear very often in the corpus. Also the term `EU` and the character `&amp` appear quite often as well. We will deal with them in later stages."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3onQO9qI4enB",
        "outputId": "d51cd702-22d1-4c97-94b7-f673e7e0af44",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "getWordFreq([my_preprocessor(x) for x in train_x])[:100]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('the', 4220),\n",
              " ('to', 4005),\n",
              " ('in', 2850),\n",
              " ('of', 2567),\n",
              " ('on', 2042),\n",
              " ('for', 1931),\n",
              " ('and', 1628),\n",
              " ('eu', 1579),\n",
              " ('is', 1310),\n",
              " ('with', 1177),\n",
              " ('exlmrk', 1112),\n",
              " ('not', 944),\n",
              " ('we', 939),\n",
              " ('it', 688),\n",
              " ('that', 669),\n",
              " ('at', 644),\n",
              " ('be', 628),\n",
              " ('will', 592),\n",
              " ('qsnmrk', 567),\n",
              " ('this', 565),\n",
              " ('are', 555),\n",
              " ('by', 538),\n",
              " ('from', 529),\n",
              " ('ukip', 520),\n",
              " ('today', 514),\n",
              " ('have', 477),\n",
              " ('my', 462),\n",
              " ('you', 431),\n",
              " ('europe', 430),\n",
              " ('now', 419),\n",
              " ('as', 417),\n",
              " ('european', 413),\n",
              " ('our', 413),\n",
              " ('about', 379),\n",
              " ('more', 347),\n",
              " ('all', 345),\n",
              " ('uk', 342),\n",
              " ('has', 335),\n",
              " ('no', 332),\n",
              " ('but', 332),\n",
              " ('@eppgroup', 329),\n",
              " ('people', 322),\n",
              " ('vote', 304),\n",
              " ('an', 295),\n",
              " ('great', 293),\n",
              " ('ep', 284),\n",
              " ('good', 284),\n",
              " ('do', 272),\n",
              " ('ttip', 270),\n",
              " ('must', 262),\n",
              " ('need', 261),\n",
              " ('support', 258),\n",
              " ('up', 257),\n",
              " ('meps', 254),\n",
              " ('labour', 252),\n",
              " ('new', 252),\n",
              " ('debate', 251),\n",
              " ('meeting', 248),\n",
              " ('parliament', 247),\n",
              " ('who', 242),\n",
              " ('just', 239),\n",
              " ('can', 237),\n",
              " ('what', 231),\n",
              " ('if', 231),\n",
              " ('they', 219),\n",
              " ('how', 218),\n",
              " ('against', 217),\n",
              " ('us', 211),\n",
              " ('so', 206),\n",
              " ('should', 206),\n",
              " ('@europarl_en', 206),\n",
              " ('he', 205),\n",
              " ('greece', 203),\n",
              " ('here', 202),\n",
              " ('right', 200),\n",
              " ('out', 192),\n",
              " ('was', 185),\n",
              " ('their', 182),\n",
              " ('only', 172),\n",
              " ('cameron', 170),\n",
              " ('@theprogressives', 167),\n",
              " ('his', 160),\n",
              " ('says', 160),\n",
              " ('work', 159),\n",
              " ('get', 158),\n",
              " ('migration', 155),\n",
              " ('want', 149),\n",
              " ('day', 148),\n",
              " ('time', 148),\n",
              " ('after', 147),\n",
              " ('me', 144),\n",
              " ('very', 144),\n",
              " ('see', 144),\n",
              " ('would', 143),\n",
              " ('mep', 143),\n",
              " ('thanks', 143),\n",
              " ('via', 143),\n",
              " ('there', 142),\n",
              " ('trade', 138),\n",
              " ('policy', 138)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 161
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cNoXo6G_hRfl"
      },
      "source": [
        "In this step I encoded the target variable to categorical labels and saved a mapping og the process."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YD9Bl-q9q5qe"
      },
      "source": [
        "encoder = preprocessing.LabelEncoder()\n",
        "train_y = encoder.fit_transform(train_y)\n",
        "valid_y = encoder.fit_transform(valid_y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQJWawR6gNcs",
        "outputId": "8a6e567f-5c0e-47f8-9e90-cfd84874e24a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "encoder.transform(['ALDE', 'ECR', 'EFDD', 'EPP', 'GUE-NGL', 'Greens-EFA', 'S&D'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 2, 3, 4, 5, 6])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 163
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jg_4SNXwbgN2"
      },
      "source": [
        "labels = {0: 'ALDE', 1: 'ECR', 2:'EFDD', 3:'EPP', 4:'GUE-NGL', 5:'Greens-EFA', 6:'S&D'}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z57J8Q_6hwJV"
      },
      "source": [
        "I will create a list of stopwords that appear very often in the corpus in order to be omitted."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZFxSnMtqFDV"
      },
      "source": [
        "stop_words = ['to', 'the', 'in', 'of', 'on', 'for', 'and', 'a', 'an', 'be', 'with', 'eu', 'is']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BQwhOwo7tF3i"
      },
      "source": [
        "## Machine Learning Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3T5B5hk54jh9"
      },
      "source": [
        "### Decision Tree"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k_LiCLodo05d"
      },
      "source": [
        "I will use a custom preprocessor that will do the following tasks:\n",
        "\n",
        "\n",
        "*   Remove any link from the tweet. (*As it appears polititians love pasting links and the tweets are full of them so no extravariance is awarded among groups*)\n",
        "*   Keep only words and mentions as is. (*they may affect the contect of the tweet if tokenazed separately*)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GQqTgL_6rpTU"
      },
      "source": [
        "Lets test the dataset after performing preprosessing and tokenization according to our functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mIVT34tz1ufa"
      },
      "source": [
        "In this step I will apply a custom version of vectorizer using the custom preprocessor I initiated."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s6Ok83VJntpz"
      },
      "source": [
        "* Count Vectorizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v4wXerXq14Xw"
      },
      "source": [
        "custom_vectorizer = CountVectorizer(preprocessor=my_preprocessor,\n",
        "                             #tokenizer=my_tokenizer,\n",
        "                             ngram_range=(1,1),\n",
        "                             stop_words = stop_words,\n",
        "                            )\n",
        "cv_matrix = custom_vectorizer.fit_transform(train_x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DAVNEBrAtWqc"
      },
      "source": [
        "score_bin = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aqOPkzHZrRr7"
      },
      "source": [
        "As we have already observe there are imbalanced classes in the dataset. To deal with this issue I will use a weighted version of all the decision tree based algorithms I test. I will take as refference the biggest class of the dataset and give it a weight of 1. Then I will distribute the weights to the other classes according to this equation:\n",
        "$$(\\frac{No of Obs. In Biggest Class}{No of Obs. in n class})^{1.1} $$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DO41jUppBZAJ"
      },
      "source": [
        "weights = {0: (sum(train_y==2)/sum(train_y==0))**1.1,\n",
        "           1: (sum(train_y==2)/sum(train_y==1))**1.1,\n",
        "           2: 1,\n",
        "           3: (sum(train_y==2)/sum(train_y==3))**1.1,\n",
        "           4: (sum(train_y==2)/sum(train_y==4))**1.1,\n",
        "           5: (sum(train_y==2)/sum(train_y==5))**1.1,\n",
        "           6: (sum(train_y==2)/sum(train_y==6))**1.1}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hclXHQpgob4L",
        "outputId": "7c279e09-a078-4fce-cb6f-e55872bb1b8c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        }
      },
      "source": [
        "weights"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 1.7281214415359492,\n",
              " 1: 2.666160669510833,\n",
              " 2: 1,\n",
              " 3: 1.5410080589415391,\n",
              " 4: 9.547342431493272,\n",
              " 5: 2.7984493563686015,\n",
              " 6: 1.0172780591017694}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 168
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IWtahqmy9HFz",
        "outputId": "47a5277c-720c-439c-bae5-1ddc1450285a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "clf = tree.DecisionTreeClassifier(class_weight=weights)\n",
        "clf.fit(cv_matrix, train_y)\n",
        "\n",
        "cv_score = cross_val_score(clf, \n",
        "                           custom_vectorizer.transform(valid_x), \n",
        "                           valid_y, cv=10)\n",
        "score_bin.append(['count vec tree', np.mean(cv_score)])\n",
        "print(np.mean(cv_score), sem(cv_score))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.42766020354175094 0.007506766601010574\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0aiRjtpta1S8",
        "outputId": "e4608a22-a182-4d73-819e-aa8bc431bdf0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        }
      },
      "source": [
        "print(classification_report(valid_y, clf.predict(custom_vectorizer.transform(valid_x)),target_names = labels.values()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        ALDE       0.37      0.35      0.36       355\n",
            "         ECR       0.31      0.35      0.33       223\n",
            "        EFDD       0.59      0.59      0.59       607\n",
            "         EPP       0.50      0.54      0.52       415\n",
            "     GUE-NGL       0.40      0.48      0.43        71\n",
            "  Greens-EFA       0.32      0.38      0.35       242\n",
            "         S&D       0.52      0.44      0.48       624\n",
            "\n",
            "    accuracy                           0.47      2537\n",
            "   macro avg       0.43      0.45      0.44      2537\n",
            "weighted avg       0.47      0.47      0.47      2537\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kWeb_DNhn6AG"
      },
      "source": [
        "* Tfidf Vectorizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JcyAujIpmBpN"
      },
      "source": [
        "tf_vectorizer = TfidfVectorizer(preprocessor=my_preprocessor,\n",
        "                             ngram_range=(1,1),\n",
        "                             stop_words = stop_words,\n",
        "                             )\n",
        "tf_matrix = tf_vectorizer.fit_transform(train_x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6OrGffy2miuz",
        "outputId": "52c08b33-b419-495f-8372-1a90c82e17ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "clf = tree.DecisionTreeClassifier(class_weight=weights)\n",
        "clf.fit(tf_matrix, train_y)\n",
        "\n",
        "cv_score = cross_val_score(clf, \n",
        "                           tf_vectorizer.transform(valid_x), \n",
        "                           valid_y, cv=10)\n",
        "print(np.mean(cv_score), sem(cv_score))\n",
        "\n",
        "matrix_clf = confusion_matrix(valid_y, clf.predict(tf_vectorizer.transform(valid_x)))\n",
        "score_bin.append(['tfidf vec tree', np.mean(cv_score)])\n",
        "print(matrix_clf.diagonal()/matrix_clf.sum(axis=1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.40560517879929037 0.005912091569219572\n",
            "[0.41971831 0.34080717 0.56672158 0.55662651 0.43661972 0.35950413\n",
            " 0.42788462]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "26SFgYceuMzv"
      },
      "source": [
        "In this step I have created 2 initial decision trees (using count vectorizer and tfidf vectorizer). As we can see the accuracy of such models is very low. Let se how much ca we improve them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A5v8gvOouiG9",
        "outputId": "320d625b-0e09-4202-d7cf-5f43b146ea92",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 214
        }
      },
      "source": [
        "score_bin"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['count vec tree', 0.4662710528907712],\n",
              " ['count vec tree', 0.4599527233330051],\n",
              " ['count vec tree', 0.46484290357529795],\n",
              " ['count vec tree', 0.4648626021865458],\n",
              " ['count vec tree', 0.4683935782527332],\n",
              " ['count vec tree', 0.46205555008371907],\n",
              " ['count vec tree', 0.46767457894218456],\n",
              " ['count vec tree', 0.4712006303555599],\n",
              " ['count vec tree', 0.4655914508027184],\n",
              " ['count vec tree', 0.46209002265340293],\n",
              " ['tfidf vec tree', 0.45784004727666694]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 252
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d7IccyrojUWN"
      },
      "source": [
        "In order to imporve the score in this model I will put the vectorizer and the decision tree algorithm in a pipeline and performe grid search to fine tune the paramenters. The parameters that I am going to test are:  \n",
        "* whether or not to use tidf or count vector\n",
        "* the minimun and maximum frequency of words usied in bag of words.\n",
        "* the range of ngramms"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B47fXTcvjEmN"
      },
      "source": [
        "count_tree = Pipeline([\n",
        "    ('vect', CountVectorizer(preprocessor=my_preprocessor, stop_words=stop_words),),\n",
        "     ('tfidf', TfidfTransformer()),\n",
        "    ('clf', tree.DecisionTreeClassifier(class_weight=weights))\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7CCnoTmy9o8G"
      },
      "source": [
        "parameters = {'vect__ngram_range': [(1, 1), (1, 2)],\n",
        "              'tfidf__use_idf': (True, False),\n",
        "              'vect__max_df':(0.5,0.7,0.9,1.0,0.3),\n",
        "              'vect__min_df': (1,5,10,20)\n",
        "             }\n",
        "\n",
        "grid_count_tree = GridSearchCV(count_tree, parameters, n_jobs=-1, cv=10)    \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A9KlkvB5-Wk4",
        "outputId": "97f24385-e133-4e60-e71e-667a6103b21a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "grid_count_tree.fit(train_x, train_y)\n",
        "\n",
        "grid_count_tree.best_params_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'tfidf__use_idf': False,\n",
              " 'vect__max_df': 0.5,\n",
              " 'vect__min_df': 5,\n",
              " 'vect__ngram_range': (1, 2)}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 177
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KEqTVA4cMhuL",
        "outputId": "1b334e15-9572-4c62-89d1-864b937b8755",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "predicted = grid_count_tree.predict(valid_x)\n",
        "score_bin.append(['grid tree', np.mean(predicted == valid_y)])\n",
        "np.mean(predicted == valid_y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4619629483642097"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 178
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SWnuKpKyNAiq",
        "outputId": "d2299692-c418-4ab1-d73d-b2cf27e8d462",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        }
      },
      "source": [
        "print(classification_report(valid_y, predicted,target_names = labels.values()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        ALDE       0.34      0.39      0.36       355\n",
            "         ECR       0.32      0.35      0.33       223\n",
            "        EFDD       0.64      0.58      0.61       607\n",
            "         EPP       0.53      0.52      0.52       415\n",
            "     GUE-NGL       0.34      0.42      0.37        71\n",
            "  Greens-EFA       0.30      0.37      0.33       242\n",
            "         S&D       0.50      0.43      0.46       624\n",
            "\n",
            "    accuracy                           0.46      2537\n",
            "   macro avg       0.42      0.44      0.43      2537\n",
            "weighted avg       0.47      0.46      0.47      2537\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N7_RSAGl1gMr"
      },
      "source": [
        "As we can see the accuracy score was freatly improved from 41% to 47,4%.The best parameters model used only single words as tokens, took the words tha appear in 10% or less of the tweets and did not use tidf vectorizer. In every case it appears that the classifier performs better at predicting correctly the class od EFDD since 64% of the instances classified as EFDD were correct and was able to retrieve 58% of all the EFDD instances which as shown by support was the second largest. Generaly speaking the classifier perfomed better on classes with more representations on the dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F4NaU5TmGMbD"
      },
      "source": [
        "### Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nKNuGJXJGOv5"
      },
      "source": [
        "naba = MultinomialNB().fit(cv_matrix, train_y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6JFuxaovGidh",
        "outputId": "96273b81-9a41-409c-a893-f62880007cae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "cv_score = cross_val_score(naba, \n",
        "                           custom_vectorizer.transform(valid_x), \n",
        "                           valid_y, cv=10)\n",
        "print(np.mean(cv_score), sem(cv_score))\n",
        "score_bin.append(['naive bayes', np.mean(cv_score)])\n",
        "matrix_naba = confusion_matrix(valid_y, naba.predict(custom_vectorizer.transform(valid_x)))\n",
        "print(matrix_naba.diagonal()/matrix_naba.sum(axis=1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.5388285456412809 0.004348594368120479\n",
            "[0.55492958 0.21524664 0.91598023 0.65301205 0.14084507 0.26033058\n",
            " 0.67467949]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fHuz6quQ45iu"
      },
      "source": [
        "As we can see the naive bayes model has better accuracy scores but performed poorly on some classes mainly due to the reason that it predicted the most common labels in most cases. I will try to improve this model using gid search and them perform a more in-depth analysis. As before I will create a pipeline of my vectorisers and the model. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_kJIjJoTNUYX"
      },
      "source": [
        "count_nb = Pipeline([\n",
        "    ('vect', CountVectorizer(preprocessor=my_preprocessor)),\n",
        "     ('tfidf', TfidfTransformer()),\n",
        "    ('nb', MultinomialNB())\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SM5al4NWNd36"
      },
      "source": [
        "parameters = {'vect__ngram_range': [(1, 1), (1, 2)],\n",
        "              'tfidf__use_idf': (True, False),\n",
        "              'vect__max_df':(0.5,1.0,0.3),\n",
        "              'vect__min_df': (1,5,10,20),\n",
        "              'nb__alpha': (1e-2,1e-1,1)\n",
        "             }\n",
        "\n",
        "grid_count_nb = GridSearchCV(count_nb, parameters, n_jobs=-1, cv=10) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6D4DE-NyNypu",
        "outputId": "5b414ccc-63e9-4876-e4c7-9f0a0d6c3c6c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        }
      },
      "source": [
        "grid_count_nb.fit(train_x, train_y)\n",
        "\n",
        "grid_count_nb.best_params_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'nb__alpha': 0.01,\n",
              " 'tfidf__use_idf': False,\n",
              " 'vect__max_df': 0.3,\n",
              " 'vect__min_df': 1,\n",
              " 'vect__ngram_range': (1, 1)}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 184
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aXw-uyEnN56U",
        "outputId": "cf12d146-80e4-4fdc-9aff-578908f0d9be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "predicted_nb = grid_count_nb.predict(valid_x)\n",
        "score_bin.append(['grid naive bayes', np.mean(predicted_nb == valid_y)])\n",
        "np.mean(predicted_nb == valid_y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6204178163184864"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 185
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pte-hKCvQkJX",
        "outputId": "a062870b-22b3-4286-8b9a-af5744cff8d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        }
      },
      "source": [
        "print(classification_report(valid_y, predicted_nb,target_names = labels.values()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        ALDE       0.56      0.58      0.57       355\n",
            "         ECR       0.51      0.29      0.37       223\n",
            "        EFDD       0.68      0.86      0.76       607\n",
            "         EPP       0.62      0.62      0.62       415\n",
            "     GUE-NGL       0.79      0.32      0.46        71\n",
            "  Greens-EFA       0.58      0.35      0.44       242\n",
            "         S&D       0.61      0.66      0.63       624\n",
            "\n",
            "    accuracy                           0.62      2537\n",
            "   macro avg       0.62      0.53      0.55      2537\n",
            "weighted avg       0.61      0.62      0.61      2537\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lM9JYhREPsKv"
      },
      "source": [
        "As it appears grid search was still able to improve the model. The optimal parameters used were:\n",
        "* The vectorizer used only single words as tokens\n",
        "* It used the words that appear in only the 30% of the tweets.\n",
        "* It did not utilized tidf scoring on the word tokens\n",
        "* The naive bayes alpha value was set to 0.1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NqLJh8uUGO5-"
      },
      "source": [
        "This version of Naive Bayes algorithm was able to outperfom all previous models. On contrary to the tree based method it predincted more instances of GUE-NGL correctly but with a lower recall score. This means that it identified less tweets as GUE-NGL but the true possitives in percentage were more. EFDD still seems to be a well defined class for classification.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k8i7L5T2RTA4"
      },
      "source": [
        "### Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "683mlhmJRUDl",
        "outputId": "53d3cbe1-22e2-423f-90a6-93f587ed0489",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 234
        }
      },
      "source": [
        "logreg = LogisticRegression().fit(cv_matrix, train_y)\n",
        "logreg_score = cross_val_score(logreg,\n",
        "                            custom_vectorizer.transform(valid_x), \n",
        "                            valid_y, \n",
        "                            cv=10)\n",
        "\n",
        "print(np.mean(logreg_score), sem(logreg_score))\n",
        "score_bin.append(['logistic regression',np.mean(logreg_score) ])\n",
        "matrix_logreg = confusion_matrix(valid_y, logreg.predict(custom_vectorizer.transform(valid_x)))\n",
        "print(matrix_logreg.diagonal()/matrix_logreg.sum(axis=1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.5463290902866392 0.0038996777366599607\n",
            "[0.55492958 0.40358744 0.82042834 0.60963855 0.33802817 0.41735537\n",
            " 0.64423077]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "amVUE6V8Rft6",
        "outputId": "2d848e43-48ac-4a0b-f833-cf9b9061cc50",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        }
      },
      "source": [
        "count_lg = Pipeline([\n",
        "    ('vect', CountVectorizer(preprocessor=my_preprocessor, \n",
        "                             ngram_range = (1,1))),\n",
        "     ('tfidf', TfidfTransformer(use_idf = False)),\n",
        "    ('lg', LogisticRegression())\n",
        "])\n",
        "\n",
        "parameters = {'tfidf__use_idf': (True, False),\n",
        "              'vect__max_df':(0.5,0.2,0.3),\n",
        "              'vect__min_df': (1,2,3),\n",
        "              'lg__penalty': (\"l1\",\"l2\") # l1 lasso l2 ridge\n",
        "             }\n",
        "\n",
        "grid_count_lg = GridSearchCV(count_lg, parameters, n_jobs=-1, cv=10) \n",
        "\n",
        "grid_count_lg.fit(train_x, train_y)\n",
        "\n",
        "print(grid_count_lg.best_params_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'lg__penalty': 'l2', 'tfidf__use_idf': True, 'vect__max_df': 0.2, 'vect__min_df': 1}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rItcfd4VRo3S",
        "outputId": "69ce6134-2c88-42e4-f802-da48804a5edd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "predicted_lg = grid_count_lg.predict(valid_x)\n",
        "score_bin.append(['grid log regression',np.mean(predicted_lg == valid_y) ])\n",
        "np.mean(predicted_lg == valid_y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6188411509657076"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 189
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bkAzXaHGjKwY",
        "outputId": "0dd46cb4-7108-4590-f783-15a9a4b37de3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        }
      },
      "source": [
        "print(classification_report(valid_y, predicted_lg,target_names = labels.values()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        ALDE       0.57      0.55      0.56       355\n",
            "         ECR       0.73      0.26      0.39       223\n",
            "        EFDD       0.65      0.86      0.74       607\n",
            "         EPP       0.66      0.61      0.63       415\n",
            "     GUE-NGL       1.00      0.18      0.31        71\n",
            "  Greens-EFA       0.64      0.31      0.42       242\n",
            "         S&D       0.56      0.72      0.63       624\n",
            "\n",
            "    accuracy                           0.62      2537\n",
            "   macro avg       0.69      0.50      0.53      2537\n",
            "weighted avg       0.64      0.62      0.60      2537\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RNwBrFvHHHhp"
      },
      "source": [
        "Using logistic regression the best perfoming predictions were in classes EFDD and EPP. It is pretty noticable that it achieved 100% precision in identifying GUE-NGL instances but wasable to retrieve only 18% of 71 of the tweets of this class."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gjBZgCFWmK1U"
      },
      "source": [
        "### Support Vector Machines Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WIjwXXVDmL7Y",
        "outputId": "3540992c-eef8-4746-ad85-21ea8c715811",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "cvma = svm.SVC().fit(cv_matrix, train_y)\n",
        "cvma_score = cross_val_score(cvma,\n",
        "                            custom_vectorizer.transform(valid_x), \n",
        "                            valid_y, \n",
        "                            cv=10)\n",
        "\n",
        "print(np.mean(cvma_score), sem(cvma_score))\n",
        "matrix_cvma = confusion_matrix(valid_y, cvma.predict(custom_vectorizer.transform(valid_x)))\n",
        "score_bin.append(['svm',np.mean(cvma_score)])\n",
        "print(matrix_cvma.diagonal()/matrix_cvma.sum(axis=1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.48127042420092747 0.006853743966591\n",
            "[0.45352113 0.15246637 0.84349259 0.53975904 0.08450704 0.23553719\n",
            " 0.75320513]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZCGF8fdmdLU",
        "outputId": "1ab3e7d1-3609-49bb-b547-c41b6ce53394",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        }
      },
      "source": [
        "count_svm = Pipeline([\n",
        "                      ('vect', CountVectorizer(preprocessor=my_preprocessor,\n",
        "                                               ngram_range = (1,1))),\n",
        "                      ('tfidf', TfidfTransformer()),\n",
        "                      ('svm', svm.SVC())\n",
        "])\n",
        "\n",
        "parameters = [{'tfidf__use_idf': (True, False),\n",
        "              'vect__max_df':(0.5,0.2,0.3),\n",
        "              'vect__min_df': (1,3),\n",
        "             },\n",
        "              {'svm__kernel': ['rbf'], 'svm__gamma': [1e-3, 1e-4],\n",
        "                     'svm__C': [1, 10, 100, 1000]},\n",
        "              {'svm__kernel': ['linear'], 'svm__C': [1, 10, 100, 1000]}]\n",
        "grid_count_svm = GridSearchCV(count_svm, parameters, n_jobs=-1, cv=10) \n",
        "\n",
        "grid_count_svm.fit(train_x, train_y)\n",
        "\n",
        "print(grid_count_svm.best_params_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'svm__C': 1, 'svm__kernel': 'linear'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tQZy2l0nxsOn",
        "outputId": "6508e9d0-e964-46b2-e5db-796897c2d87f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "predicted_svm = grid_count_svm.predict(valid_x)\n",
        "score_bin.append(['grid svm',np.mean(predicted_svm == valid_y)])\n",
        "np.mean(predicted_svm == valid_y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.625147812376823"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 193
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ic-3Yo2Vx9Ca",
        "outputId": "aa8c8aa2-b76e-4db2-d19d-ad9521daac8f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        }
      },
      "source": [
        "print(classification_report(valid_y, predicted_svm,target_names = labels.values()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        ALDE       0.53      0.57      0.55       355\n",
            "         ECR       0.59      0.31      0.41       223\n",
            "        EFDD       0.68      0.86      0.76       607\n",
            "         EPP       0.67      0.61      0.64       415\n",
            "     GUE-NGL       0.81      0.31      0.45        71\n",
            "  Greens-EFA       0.58      0.38      0.46       242\n",
            "         S&D       0.60      0.68      0.64       624\n",
            "\n",
            "    accuracy                           0.63      2537\n",
            "   macro avg       0.64      0.53      0.56      2537\n",
            "weighted avg       0.62      0.63      0.61      2537\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FSHEY0KjH7qe"
      },
      "source": [
        "So far SVM classifier appears to be the most suitable for our problem. It was able to predict the classes correctly for 63% of the tweets in the test set, retrieving a greater percentage of tweets in most categories. As always classes with more representations in the data set seem to be easier to predict for my models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4UxmXSNZFlc1"
      },
      "source": [
        "In the following classifiers I did not performed grid search due to resources limitation and since I already exausted the requirements of this excersize. Since I already explained in detail the classification reports of the previous models I will not go into any further detail in the following classiers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yox09dAbE9Ur"
      },
      "source": [
        "### Baging"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hCd6-rxI31c0"
      },
      "source": [
        "Although Naive Baise seems to perform slightly better on our datase still the results are far from optimal. In my quest to create a better clasifier I will utilise Bagging "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XgLA3sr74ePn"
      },
      "source": [
        "bagging_clf = BaggingClassifier(tree.DecisionTreeClassifier(random_state=0, class_weight=weights), \n",
        "                                n_estimators=50, \n",
        "                                n_jobs=-1).fit(cv_matrix, train_y)\n",
        "bagged_cv_score = cross_val_score(bagging_clf, \n",
        "                                  custom_vectorizer.transform(valid_x), \n",
        "                                  valid_y, \n",
        "                                  cv=5)\n",
        "\n",
        "print(np.mean(bagged_cv_score), sem(bagged_cv_score))\n",
        "matrix_bg = confusion_matrix(valid_y, bagging_clf.predict(custom_vectorizer.transform(valid_x)))\n",
        "score_bin.append(['bagging trees', np.mean(bagged_cv_score)])\n",
        "print(matrix_bg.diagonal()/matrix_bg.sum(axis=1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hO0eOS3P7DBn"
      },
      "source": [
        "The accuracy of the bagged model using 50 subsets of the data set is more accurate but still Naive Bayes performs better "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vXVfPINg7Erm"
      },
      "source": [
        "### Random Forests"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UmIsf2oP7Jni",
        "outputId": "861abce2-a0db-4d82-ff4f-a126abc66599",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "frst = RandomForestClassifier(n_estimators=50, \n",
        "                              max_depth=200,\n",
        "                              min_samples_split=3, \n",
        "                              random_state=0, \n",
        "                              class_weight=weights).fit(cv_matrix, train_y)\n",
        "frst_score = cross_val_score(frst, \n",
        "                                  custom_vectorizer.transform(valid_x), \n",
        "                                  valid_y, \n",
        "                                  cv=5)\n",
        "\n",
        "print(np.mean(frst_score), sem(frst_score))\n",
        "score_bin.append(['Random Forest', np.mean(frst_score)])\n",
        "\n",
        "matrix_frst = confusion_matrix(valid_y, frst.predict(custom_vectorizer.transform(valid_x)))\n",
        "print(matrix_frst.diagonal()/matrix_frst.sum(axis=1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.5171403500597929 0.007444407465315333\n",
            "[0.47887324 0.31838565 0.80560132 0.58072289 0.50704225 0.42561983\n",
            " 0.54326923]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2DTirTmv7-J1"
      },
      "source": [
        "### Extra Trees Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-s0JNLYi8Coh",
        "outputId": "59d2a33b-c39d-4418-a091-2d6915818196",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "ext = ExtraTreesClassifier(n_estimators=50, \n",
        "                            max_depth=500,\n",
        "                            min_samples_split=4,\n",
        "                            class_weight=weights,\n",
        "                            random_state=0).fit(cv_matrix, train_y)\n",
        "ext_score = cross_val_score(ext,\n",
        "                            custom_vectorizer.transform(valid_x), \n",
        "                            valid_y, \n",
        "                            cv=5)\n",
        "\n",
        "print(np.mean(ext_score), sem(ext_score))\n",
        "matrix_ext = confusion_matrix(valid_y, ext.predict(custom_vectorizer.transform(valid_x)))\n",
        "score_bin.append(['Extra Trees', np.mean(ext_score)])\n",
        "print(matrix_ext.diagonal()/matrix_ext.sum(axis=1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.5277819192719253 0.00790064991218037\n",
            "[0.48732394 0.35874439 0.82701812 0.61927711 0.53521127 0.42975207\n",
            " 0.56570513]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7BftBIVq8tO8"
      },
      "source": [
        "As it appears there is not much difference between the extremely randomised trees and the random forest classifier as they performed similarly (still slightly worse than Naive Bayes classifier)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2GvHTyqU9L-6"
      },
      "source": [
        "### AdaBoost Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zmkHoiBH-ok-",
        "outputId": "54844da3-ec00-4b47-dfa7-f6c362e3e797",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "adab = AdaBoostClassifier(tree.DecisionTreeClassifier(class_weight=weights,\n",
        "                                                      max_depth = 300),\n",
        "                                                      n_estimators=500).fit(cv_matrix, train_y)\n",
        "adab_score = cross_val_score(adab,\n",
        "                            custom_vectorizer.transform(valid_x), \n",
        "                            valid_y, \n",
        "                            cv=5)\n",
        "\n",
        "print(np.mean(adab_score), sem(adab_score))\n",
        "score_bin.append(['AdaBoost', np.mean(adab_score)])\n",
        "matrix_adab = confusion_matrix(valid_y, adab.predict(custom_vectorizer.transform(valid_x)))\n",
        "print(matrix_adab.diagonal()/matrix_adab.sum(axis=1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.4233324014971501 0.006204119522070765\n",
            "[0.3943662  0.16591928 0.80230643 0.53493976 0.14084507 0.20661157\n",
            " 0.71794872]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FicAqaoDENUs"
      },
      "source": [
        "Adaptive boosting does not seem to work well with the given dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Ic2xwutKAvr"
      },
      "source": [
        "### XGBoost Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XyAQwg1YKKdI",
        "outputId": "a208d4e4-e1fb-45e5-ecb9-bac926a0c9c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "xgboost = xgb.XGBClassifier(n_estimators=100,\n",
        "                            max_depth=300, \n",
        "                            learning_rate=0.1, \n",
        "                            subsample=0.4).fit(cv_matrix, train_y)\n",
        "\n",
        "xgboost_score = cross_val_score(xgboost,\n",
        "                            custom_vectorizer.transform(valid_x), \n",
        "                            valid_y, \n",
        "                            cv=10)\n",
        "\n",
        "print(np.mean(xgboost_score), sem(xgboost_score))\n",
        "matrix_xgboost = confusion_matrix(valid_y, xgboost.predict(custom_vectorizer.transform(valid_x)))\n",
        "score_bin.append(['XGBoost', np.mean(xgboost_score)])\n",
        "print(matrix_xgboost.diagonal()/matrix_xgboost.sum(axis=1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.5005944415050886 0.006641021878610744\n",
            "[0.52112676 0.39461883 0.80065898 0.60481928 0.4084507  0.38016529\n",
            " 0.61538462]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eRBfAhYBPnIX"
      },
      "source": [
        "pd.DataFrame(score_bin).to_excel('scores.xlsx')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iX7tMTMwJJAO"
      },
      "source": [
        "In this step the scores of all classifiers were stored in order to avaid re-running them again."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HCNCgepS212n"
      },
      "source": [
        "score_bin = pd.read_excel('scores.xlsx')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZqKzBRAMguYj"
      },
      "source": [
        "### Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mdLziDzXgxdR",
        "outputId": "976c180f-ac8a-4130-a5ed-fd5f143f0238",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "from keras import backend as K\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding,Reshape,Concatenate,Conv2D,MaxPool2D, LSTM, GRU, SpatialDropout1D, MaxPooling1D, Conv1D, Flatten, GlobalMaxPool1D, Bidirectional, TimeDistributed\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.layers import Dropout\n",
        "from keras.optimizers import Adam\n",
        "from sklearn.utils import class_weight\n",
        "from gensim.models import Word2Vec \n",
        "from keras.initializers import Constant\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iqSIOo_tzp6S"
      },
      "source": [
        "train_X = [my_preprocessor(x) for x in train_X]\n",
        "test_X = [my_preprocessor(x) for x in valid_X]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sbLFE8YH1q8c"
      },
      "source": [
        "max_len = 0\n",
        "for sentence in train_X:\n",
        "  if max_len < len(sentence.split()):\n",
        "     max_len = len(sentence.split())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H4DRdj5vUC21",
        "outputId": "b6530df0-f047-4c0b-cc4f-6e0a73f1453a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "max_len"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "32"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N51xGjw_JjNC"
      },
      "source": [
        "The largest tweet consists of 32 words. I will use that as refference and pad all the rest in order to create a single input size of 32 tokens. I will also use the 8000 most common words  and represent each word with an embedding size of 200 lenght. I will not use pretraned embeddings or train my own separately as it is out of the scope of my assignement. The embedings will be trained will fitting the neural network model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "adUBJ0oklhRl",
        "outputId": "e6541304-3859-4cfd-f6c0-ef7ed23418ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# The maximum number of words to be used. (most frequent)\n",
        "MAX_NB_WORDS = 8000\n",
        "# This is fixed.\n",
        "EMBEDDING_DIM = 200\n",
        "\n",
        "tokenizer = Tokenizer(num_words=MAX_NB_WORDS,\n",
        "                      char_level = False)\n",
        "tokenizer.fit_on_texts(train_X)\n",
        "word_index = tokenizer.word_index\n",
        "print('Found %s unique tokens.' % len(word_index))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 13795 unique tokens.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gTYGgdg9nQO5",
        "outputId": "0578e7a3-9a6e-42b4-f71c-200fcf681637",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X = tokenizer.texts_to_sequences(train_X)\n",
        "X = pad_sequences(X, maxlen=32)\n",
        "print('Shape of data tensor:', X.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of data tensor: (7608, 32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r3hW5DExzvqE"
      },
      "source": [
        "test_X = tokenizer.texts_to_sequences(test_X)\n",
        "test_X = pad_sequences(test_X, maxlen=32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7qvs5LwxKXwP"
      },
      "source": [
        "I will convert each class in a vector representation of 0 and 1 accordingly."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k7cTtbu1nzFE"
      },
      "source": [
        "Y = pd.get_dummies(train_Y).values\n",
        "test_Y = pd.get_dummies(valid_Y).values\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jXhbe5V3Kj6-"
      },
      "source": [
        "Since there is imbalance among the classes of the dataset I will set weights."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C9zgQ6qS4KUp"
      },
      "source": [
        "class_weights = class_weight.compute_class_weight('balanced',\n",
        "                                                 np.unique(train_Y),\n",
        "                                                  train_Y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uy9TrQbXKs5i"
      },
      "source": [
        "The main logic behind this neural network is that after creating the embeddings I will use a max pooling layer to reduce dimentionality and reduce overfitting. The I initialised a dropout layer switching of 10% of the neurons at random. Then I will add a dene layer of size 7 which will be my output layer and convert all the inputs of the previous layers to class representations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TnRfc0-Oi6PA",
        "outputId": "ae330ae5-f33c-4cb6-80bd-846be2c01e92",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 581
        }
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(MAX_NB_WORDS, \n",
        "                    EMBEDDING_DIM, \n",
        "                    input_length=X.shape[1], \n",
        "                    trainable=True))\n",
        "model.add(GlobalMaxPool1D())\n",
        "model.add(Dropout(0.1))\n",
        "model.add(Dense(7, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.001), metrics=['accuracy'])\n",
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 32, 200)           1600000   \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_1 (Glob (None, 200)               0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 200)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 7)                 1407      \n",
            "=================================================================\n",
            "Total params: 1,601,407\n",
            "Trainable params: 1,601,407\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MBj8T9089krD"
      },
      "source": [
        "I will let mymodel train for 100 epochs whith a batch size of 32 training samples. In each epoch the initial training set will be further split to training set where my model will try to detect any patterns and a validation set, where my model would validate its learning and adjust its internal parameters accordingly. I order to avoid training my model while being overfit I set an early callback, which basically will stop the trainig process if the validation loss score does not change by a value larger than 0.0001 in 5 epochs. Finally, in order to address the issue of imbalance in my dataset, I gave different weights to each class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x5HfAs7VjhY6",
        "outputId": "d2715052-17f8-4b5c-eba6-967e4c9bb1c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 819
        }
      },
      "source": [
        "epochs = 100\n",
        "batch_size = 64\n",
        "\n",
        "history = model.fit(X, Y, epochs=epochs, \n",
        "                    batch_size=batch_size,\n",
        "                    validation_split=0.1,\n",
        "                    callbacks=[EarlyStopping(monitor='val_loss', patience=5, min_delta=0.0001)],\n",
        "                    class_weight = class_weights\n",
        "                    )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Train on 6847 samples, validate on 761 samples\n",
            "Epoch 1/100\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "6847/6847 [==============================] - 16s 2ms/step - loss: 1.8208 - acc: 0.2902 - val_loss: 1.7001 - val_acc: 0.3916\n",
            "Epoch 2/100\n",
            "6847/6847 [==============================] - 0s 63us/step - loss: 1.5894 - acc: 0.4795 - val_loss: 1.4829 - val_acc: 0.4901\n",
            "Epoch 3/100\n",
            "6847/6847 [==============================] - 0s 63us/step - loss: 1.3095 - acc: 0.6044 - val_loss: 1.3003 - val_acc: 0.5677\n",
            "Epoch 4/100\n",
            "6847/6847 [==============================] - 0s 68us/step - loss: 1.0517 - acc: 0.7327 - val_loss: 1.1813 - val_acc: 0.6058\n",
            "Epoch 5/100\n",
            "6847/6847 [==============================] - 0s 66us/step - loss: 0.8218 - acc: 0.8126 - val_loss: 1.1074 - val_acc: 0.6255\n",
            "Epoch 6/100\n",
            "6847/6847 [==============================] - 0s 65us/step - loss: 0.6210 - acc: 0.8779 - val_loss: 1.0616 - val_acc: 0.6373\n",
            "Epoch 7/100\n",
            "6847/6847 [==============================] - 0s 66us/step - loss: 0.4604 - acc: 0.9198 - val_loss: 1.0397 - val_acc: 0.6360\n",
            "Epoch 8/100\n",
            "6847/6847 [==============================] - 0s 67us/step - loss: 0.3345 - acc: 0.9483 - val_loss: 1.0275 - val_acc: 0.6413\n",
            "Epoch 9/100\n",
            "6847/6847 [==============================] - 0s 71us/step - loss: 0.2440 - acc: 0.9670 - val_loss: 1.0283 - val_acc: 0.6360\n",
            "Epoch 10/100\n",
            "6847/6847 [==============================] - 0s 68us/step - loss: 0.1788 - acc: 0.9826 - val_loss: 1.0322 - val_acc: 0.6373\n",
            "Epoch 11/100\n",
            "6847/6847 [==============================] - 0s 68us/step - loss: 0.1322 - acc: 0.9896 - val_loss: 1.0416 - val_acc: 0.6360\n",
            "Epoch 12/100\n",
            "6847/6847 [==============================] - 0s 69us/step - loss: 0.1003 - acc: 0.9942 - val_loss: 1.0534 - val_acc: 0.6360\n",
            "Epoch 13/100\n",
            "6847/6847 [==============================] - 0s 68us/step - loss: 0.0759 - acc: 0.9971 - val_loss: 1.0679 - val_acc: 0.6360\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "meV_RhxbvNkw",
        "outputId": "81119034-3277-4e46-949e-061ba8fc27fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "# summarize history for accuracy\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3dd3hW5fnA8e+dTUICISxJwIQlS4aG\noSjiRlFwg4oVW6F1FLGTLmut/VVb66oTFTfDgYotDrQMN0T23iNAQhgJScjO/fvjHOJLSOAl5M1J\n8t6f68qV9+z7ZDz3Oc9zzvOIqmKMMSZ4hXgdgDHGGG9ZIjDGmCBnicAYY4KcJQJjjAlylgiMMSbI\nWSIwxpggZ4nABBUReUVEHvRz3a0iclGgYzLGa5YIjDEmyFkiMKYBEpEwr2MwjYclAlPvuFUyvxaR\n5SKSLyIviUgbEflIRHJF5DMRifdZf4SIrBKRbBGZJyLdfZb1E5HF7nYzgKhKx7pCRJa6234tIr39\njHG4iCwRkYMiskNE7q+0/Bx3f9nu8rHu/CYi8i8R2SYiOSLypTtvqIikV/FzuMj9fL+IvCMib4jI\nQWCsiAwQkW/cY+wWkadEJMJn+54iMkdE9otIpoj8XkTaisghEUnwWe8MEckSkXB/zt00PpYITH11\nLXAx0BW4EvgI+D3QCufvdgKAiHQFpgET3WWzgQ9FJMItFN8HXgdaAG+7+8Xdth8wBfgpkAA8D8wS\nkUg/4ssHfgQ0B4YDd4jIVe5+T3Xj/bcbU19gqbvdI8CZwNluTL8Byv38mYwE3nGP+SZQBtwLtATO\nAi4E7nRjiAU+Az4G2gGdgc9VNQOYB9zgs99bgOmqWuJnHKaRsURg6qt/q2qmqu4EvgC+U9UlqloI\nvAf0c9cbBfxXVee4BdkjQBOcgnYQEA48rqolqvoOsMjnGOOB51X1O1UtU9VXgSJ3u2NS1XmqukJV\ny1V1OU4yOs9dfBPwmapOc4+7T1WXikgI8GPgHlXd6R7za1Ut8vNn8o2qvu8es0BVv1fVb1W1VFW3\n4iSywzFcAWSo6r9UtVBVc1X1O3fZq8AYABEJBW7ESZYmSFkiMPVVps/ngiqmm7qf2wHbDi9Q1XJg\nB5DoLtupR/asuM3n86nAL92qlWwRyQbau9sdk4gMFJG5bpVKDvAznCtz3H1sqmKzljhVU1Ut88eO\nSjF0FZH/iEiGW130f37EAPAB0ENEUnDuunJUdWENYzKNgCUC09DtwinQARARwSkEdwK7gUR33mEd\nfD7vAP6mqs19vqJVdZofx50KzALaq2oz4Dng8HF2AJ2q2GYvUFjNsnwg2uc8QnGqlXxV7ir4WWAt\n0EVV43Cqznxj6FhV4O5d1Vs4dwW3YHcDQc8SgWno3gKGi8iFbmPnL3Gqd74GvgFKgQkiEi4i1wAD\nfLZ9AfiZe3UvIhLjNgLH+nHcWGC/qhaKyACc6qDD3gQuEpEbRCRMRBJEpK97tzIFeFRE2olIqIic\n5bZJrAei3OOHA38EjtdWEQscBPJEpBtwh8+y/wCniMhEEYkUkVgRGeiz/DVgLDACSwRBzxKBadBU\ndR3Ole2/ca64rwSuVNViVS0GrsEp8PbjtCfM9Nk2DRgHPAUcADa66/rjTuABEckF7sNJSIf3ux24\nHCcp7cdpKO7jLv4VsAKnrWI/8DAQoqo57j5fxLmbyQeOeIqoCr/CSUC5OElthk8MuTjVPlcCGcAG\n4Hyf5V/hNFIvVlXf6jIThMQGpjEmOInI/4Cpqvqi17EYb1kiMCYIiUh/YA5OG0eu1/EYb1nVkDFB\nRkRexXnHYKIlAQN2R2CMMUHP7giMMSbINbiOq1q2bKnJycleh2GMMQ3K999/v1dVK7+bAjTARJCc\nnExaWprXYRhjTIMiItU+JmxVQ8YYE+QsERhjTJCzRGCMMUGuwbURVKWkpIT09HQKCwu9DqVRiIqK\nIikpifBwG6fEmGAQsEQgIlNw+kTfo6q9qlguwBM4fbIcAsaq6uKaHCs9PZ3Y2FiSk5M5sqNJc6JU\nlX379pGenk5KSorX4Rhj6kAgq4ZeAYYdY/llQBf3azxOl7o1UlhYSEJCgiWBWiAiJCQk2N2VMUEk\nYIlAVRfg9K5YnZHAa+r4FmguIqfU9HiWBGqP/SyNCS5ethEkcuSIS+nuvN2VVxSR8Th3DXTo0KHy\nYmOMqfdUldJypbCkjKLScuerpIzCknKKSn+YV7G8pIxC9/vhZRd2a02f9s1rPbYG0VisqpOByQCp\nqan1rnOk7Oxspk6dyp133nlC211++eVMnTqV5s1r/xdrjDlx5eVKfnEp+UVl5BWVcqi4lLwiZzq/\nqNRdVkqeO+0sL+NQUalbWJdVKszLKSwto8gt7MtPsvRqHRvZ6BLBTpwhBQ9Lcuc1ONnZ2TzzzDNH\nJYLS0lLCwqr/Ec+ePTvQoRkTNErLyskuKOFAfjEHDpWwP7+YA4eKOVhQ4hbiZW4hXnrE9OGC/VBx\nKYeKy/w+XkxEKDGRYTSNDKNJRChR4aFEhoUQGxVOZFiI+xVKZHhIxbLD86LCf1gWGRZCZMVy53vF\n+uE/zIsMCwlYta2XiWAWcLeITAcG4gygfVS1UEMwadIkNm3aRN++fQkPDycqKor4+HjWrl3L+vXr\nueqqq9ixYweFhYXcc889jB8/Hvihu4y8vDwuu+wyzjnnHL7++msSExP54IMPaNKkicdnZow3ysqV\n7ENOQV5RqOcXs/9QMdmVpg8X/DkFJcfcp2/BHRMZRkxkKG3jotzPYTSNDCU64sjlTSPDfOa505Fh\nRIeHEhLSeNrSAvn46DRgKNBSRNKBPwPhAKr6HDAb59HRjTiPj95WG8f9y4erWL3rYG3sqkKPdnH8\n+cqe1S5/6KGHWLlyJUuXLmXevHkMHz6clStXVjx+OWXKFFq0aEFBQQH9+/fn2muvJSEh4Yh9bNiw\ngWnTpvHCCy9www038O677zJmzJhaPQ9jvKaq7MwuYH1mLhv35LEvr7jiyn1/vlvIHyomp6CE6nrI\njwoPoUV0BPExEbSIiSApPpoW0eEV0/HR7ldMOPHRETRrEk6TRlZw17aAJQJVvfE4yxW4K1DH99KA\nAQOOeAb/ySef5L333gNgx44dbNiw4ahEkJKSQt++fQE488wz2bp1a53Fa0wg7M0rYn1GLmszclmf\nmcu6zFw2ZOaRV1RasU5EWAgJMT8U3O2aN6kozFvERNA8OvyI6fjoCJpEhHp4Vo1Tg2gsPhHHunKv\nKzExMRWf582bx2effcY333xDdHQ0Q4cOrfIZ/cjIyIrPoaGhFBQU1Emsxpys3MISp6DPyHO/OwX/\nvvziinXio8M5rW0s156RSNe2sZzWJpYurWOJaxJmjyvXA40uEXghNjaW3NyqR/zLyckhPj6e6Oho\n1q5dy7ffflvH0RlTOwpLyti4J6/i6n59Ri7rM/PYmf3DRUtMRChd2sRyUfc2nNY2ltPaxtK1TSwt\nm0ZYgV+PWSKoBQkJCQwePJhevXrRpEkT2rRpU7Fs2LBhPPfcc3Tv3p3TTjuNQYMGeRipMcdXVq5s\n2Zt/xNX9uoxctu7Lr3j8MSI0hE6tm9I/OZ6b23bgtDZOgZ/YvInVxTdADW7M4tTUVK08MM2aNWvo\n3r27RxE1TvYzDQ6qyrZ9h1iWns3y9ByWp2ezcudBCkqcxyhDBJITYujaJraiSue0tk1JToghLNQ6\nL25IROR7VU2tapndERgTJFSV3TmFFQX+4e8HC53G28iwEHq2i2NU//acntiM09rG0rl1U6LCrXG2\nsbNEYEwjtS+vyC3snQJ/WXoOe/OKAAgLEU5rG8vw3u3ok9SM3knN6dKmKeF2lR+ULBEY0wgcLCxh\nZXoOy3yu9g834opAp1ZNGdK1JX2SmtM7qRndT4mzK31TwRKBMQ1MQXEZq3blHFHFs3lvfsXy9i2a\n0LdDc249+1R6JzWnV2Izmkbav7qpnv11GFPPqSrrM/P4dFUGc9ZksmrXQcrcx3dax0bSO6k5V/dL\npHf75vRObEZ8TITHEZuGxhKBMfVQWbmyZPsBPl2dySerMti27xAA/To0547zOtE7qRl92jenTVyU\nx5GaxsASgQeaNm1KXl4eu3btYsKECbzzzjtHrTN06FAeeeQRUlOrfNoLgMcff5zx48cTHR0NWLfW\nDV1RaRlfb9zHp6szmLN6D3vziggPFc7q1JJx53bkkh5taG0FvwkASwQeateuXZVJwF+PP/44Y8aM\nqUgE1q11w3OwsIR567L4ZFUG89buIb+4jJiIUIZ2a80lPdpwfrfWxEWFex2maeQsEdSCSZMm0b59\ne+66y+lD7/777ycsLIy5c+dy4MABSkpKePDBBxk5cuQR223dupUrrriClStXUlBQwG233cayZcvo\n1q3bEX0N3XHHHSxatIiCggKuu+46/vKXv/Dkk0+ya9cuzj//fFq2bMncuXMrurVu2bIljz76KFOm\nTAHg9ttvZ+LEiWzdutW6u64H9hwsZM6aTD5Zlck3m/ZSUqa0bBrBiL7tuKRHW87unEBkmD3RY+pO\n40sEH02CjBW1u8+2p8NlD1W7eNSoUUycOLEiEbz11lt88sknTJgwgbi4OPbu3cugQYMYMWJEtf2t\nPPvss0RHR7NmzRqWL1/OGWecUbHsb3/7Gy1atKCsrIwLL7yQ5cuXM2HCBB599FHmzp1Ly5Ytj9jX\n999/z8svv8x3332HqjJw4EDOO+884uPjrbtrj2zOyquo71+yPRuAUxOiuW1wCpf0aEO/DvGEWtcM\nxiONLxF4oF+/fuzZs4ddu3aRlZVFfHw8bdu25d5772XBggWEhISwc+dOMjMzadu2bZX7WLBgARMm\nTACgd+/e9O7du2LZW2+9xeTJkyktLWX37t2sXr36iOWVffnll1x99dUVvaBec801fPHFF4wYMcK6\nu64jqsry9Bw+XZ3Bp6sy2bAnD4BeiXH84uKuXNqzLV3bNLWO2Ey90PgSwTGu3APp+uuv55133iEj\nI4NRo0bx5ptvkpWVxffff094eDjJyclVdj99PFu2bOGRRx5h0aJFxMfHM3bs2Brt5zDr7jpwSsrK\nWbhlP5+symDO6kx25xQSGiIMSG7BTQM7cEnPtiQ2t2o4U/80vkTgkVGjRjFu3Dj27t3L/Pnzeeut\nt2jdujXh4eHMnTuXbdu2HXP7IUOGMHXqVC644AJWrlzJ8uXLATh48CAxMTE0a9aMzMxMPvroI4YO\nHQr80P115aqhc889l7FjxzJp0iRUlffee4/XX389IOdtnDr/KV9tZdrC7eQUlBAVHsKQLq345SWn\ncWG31vZcv6n3LBHUkp49e5Kbm0tiYiKnnHIKN998M1deeSWnn346qampdOvW7Zjb33HHHdx22210\n796d7t27c+aZZwLQp08f+vXrR7du3Wjfvj2DBw+u2Gb8+PEMGzaMdu3aMXfu3Ir5Z5xxBmPHjmXA\ngAGA01jcr18/qwaqZZuy8nhhwWZmLt5JaXk5l/Zsy1X9EhnSpZWNomUaFOuG2lTJfqbVW7z9AM/P\n38SnqzOJCA3h+tQkbj+nI8ktY46/sTEe8awbahEZBjwBhAIvqupDlZafCkwBWgH7gTGqmh7ImIyp\nifJyZe66PTw/fzMLt+6nWZNw7j6/M7eenUzLppHH34Ex9VjAEoGIhAJPAxcD6cAiEZmlqqt9VnsE\neE1VXxWRC4C/A7cEKiZjTlRxaTmzlu1i8oJNrM/Mo12zKO67ogej+rcnxjpyM41EIP+SBwAbVXUz\ngIhMB0YCvomgB/AL9/Nc4P2aHkxV7VG8WtLQqgsDIa+olOkLt/PSl1vYnVNIt7axPDaqD1f0bmd9\n9ptGJ5CJIBHY4TOdDgystM4y4Bqc6qOrgVgRSVDVfb4rich4YDxAhw4djjpQVFQU+/btIyEhwZLB\nSVJV9u3bR1RUcPZpsye3kFe+2srr324jt7CUQR1b8H/XnM7Qrq3sb8s0Wl7f2/4KeEpExgILgJ1A\nWeWVVHUyMBmcxuLKy5OSkkhPTycrKyuw0QaJqKgokpKSvA6jTm3OyuOFL7bw7uJ0SsrKGdazLT89\nrxN921sHfqbxC2Qi2Am095lOcudVUNVdOHcEiEhT4FpVzT7RA4WHh5OSknISoZpgtXRHNs/N28Qn\nqzMIDw3hujOTGHduR1LsCSATRAKZCBYBXUQkBScBjAZu8l1BRFoC+1W1HPgdzhNExgSUqjJvfRbP\nz9/Et5v3ExcVxp1DO3Hr2cm0jg3OKjET3AKWCFS1VETuBj7BeXx0iqquEpEHgDRVnQUMBf4uIopT\nNXRXoOIxpqSsnA+X7WLygs2szcjllGZR/HF4d0YP6GBDOZqg1iheKDPmWA4VlzJt4Q5e+mIzu3IK\n6dqmKT8d0okr+7QjIsyeADLBwbMXyozx2uLtB7hn+hJ27C9gQEoLHry6F0O7tibEunw2poIlAtMo\nlZUrz87byGOfbaBtXBTTxg3irE4JXodlTL1kicA0OruyC7h3xlK+27KfK3qfwt+uPp1mTWy4R2Oq\nY4nANCofr9zNb99dQUlZOf+8rjfXnZlkL4IZcxyWCEyjcKi4lL/+ZzXTFu6gd1Iznhjdz94FMMZP\nlghMg7dqVw4Tpi1h8958fnZeJ35xcVd7GsiYE2CJwDRY5eXKlK+28I+P19E8Opw3fjKQwZ1bHn9D\nY8wRLBGYBikrt4hfvb2M+euzuKh7G/5xXW9a2JCQxtSIJQLT4Mxdt4dfv72M3MJS/npVL8YM7GAN\nwsacBEsEpsEoLCnj4Y/X8vJXW+nWNpap4wbRtU2s12EZ0+BZIjANwsY9ufx82lLW7D7I2LOTmXRZ\nN6LCbYB4Y2qDJQJTr6kqUxdu56//WU10RBgv3ZrKhd3beB2WMY2KJQJTbx3IL2bSzOV8siqTc7u0\n5F/X96F1nHUTbUxts0Rg6qWvN+3lFzOWsS+/iD9c3p2fnJNiHcUZEyCWCEy9UlJWzmNz1vPs/E2k\nJMTw4q2D6ZXYzOuwjGnULBGYemPbvnwmTF/Ksh3ZjEptz31X9iDGBowxJuDsv8zUCzMXp/On91cS\nGiI8fdMZDO99itchGRM0LBEYTx0sLOG+91fy/tJdDEhuwWOj+5LYvInXYRkTVCwRGM9sysrjx68s\nIv1AAb+4uCt3nd+ZUGsQNqbOBbSLRhEZJiLrRGSjiEyqYnkHEZkrIktEZLmIXB7IeEz9kbZ1P9c+\n+zX5RaXMGD+ICRd2sSRgjEcClghEJBR4GrgM6AHcKCI9Kq32R+AtVe0HjAaeCVQ8pv74aMVubnrx\nO+KjI5h5x2BSk1t4HZIxQS2QdwQDgI2qullVi4HpwMhK6ygQ535uBuwKYDymHnjpyy3cOXUxvdrF\n8e4dZ9MhIdrrkIwJeoFsI0gEdvhMpwMDK61zP/CpiPwciAEuqmpHIjIeGA/QoUOHWg/UBF55ufLg\nf9cw5astDOvZlsdH97W+goypJ7wexulG4BVVTQIuB14XkaNiUtXJqpqqqqmtWrWq8yDNySksKePu\naYuZ8tUWxp6dzNM3n2FJwJh6JJB3BDuB9j7TSe48Xz8BhgGo6jciEgW0BPYEMC5Th7IPFTPutTQW\nbT3AH4c7XUXY2AHG1C+BvCNYBHQRkRQRicBpDJ5VaZ3twIUAItIdiAKyAhiTqUM79h/imme/ZtmO\nHJ66qR+3n9vRkoAx9VDA7ghUtVRE7gY+AUKBKaq6SkQeANJUdRbwS+AFEbkXp+F4rKpqoGIydWdF\neg63vbKIkrJy3rh9IANS7MkgY+qrgL5QpqqzgdmV5t3n83k1MDiQMZi6N3ftHu6aupj46Aimjx9I\n59Y2ipgx9Zm9WWxq1fSF2/nD+yvpfkosU27tb+MHGNMAWCIwtUJVeWzOep7830bO69qKp28+g6bW\nc6gxDYL9p5qTVlxazu9mruDdxemMSm3Pg1f3IjzU6yeTjTH+skRgTkpuYQl3vrmYLzbs5d6LujLh\nws72ZJAxDYwlAlNjGTmF3PbKIjZk5vKP63pzQ2r7429kjKl3LBGYGlmfmcvYKQvJKShhytj+DOlq\nb3wb01BZIjAn7JtN+xj/ehpNwkN562dn0bOdjSlsTENmicCckA+W7uTXby+nQ0I0r9zWn6R46z3U\nmIbOEoHxi6ry3PzNPPzxWgamtGDyLak0iw73OixjTC2wRGCOq6xcuX/WKl7/dhtX9mnHI9f3JjLM\neg81prGwRGCOqaC4jAnTlzBndSY/HdKR3w7rRogNKWlMo2KJwFRrX14RP3k1jWXp2Twwsic/OivZ\n65CMMQFgicBUaVd2ATe+8C0ZOYU8N+ZMLu3Z1uuQjDEBYonAHKWsXLln+hL25RUzddwgzjw13uuQ\njDEBZInAHOW5+ZtYtPUAj43qY0nAmCBgPYOZIyxPz+axOeu5sk87ruqb6HU4xpg6YInAVDhUXMrE\n6UtpHRvJgyN7WedxxgQJqxoyFf76nzVs2ZfP1NsH2ctixgQRv+4IRGSmiAwXEbuDaKQ+XZXBtIXb\nGT+kI2d1SvA6HGNMHfK3YH8GuAnYICIPichp/mwkIsNEZJ2IbBSRSVUsf0xElrpf60Uk+wRiN7Vk\nT24hk2auoGe7OH55sV+/WmNMI+JX1ZCqfgZ8JiLNgBvdzzuAF4A3VLWk8jYiEgo8DVwMpAOLRGSW\nO2D94f3e67P+z4F+J3My5sSpKr9+ezn5RaU8MbovEWF202dMsPH7v15EEoCxwO3AEuAJ4AxgTjWb\nDAA2qupmVS0GpgMjj3GIG4Fp/sZjaserX29l/vos/ji8O51bx3odjjHGA37dEYjIe8BpwOvAlaq6\n2100Q0TSqtksEdjhM50ODKxm/6cCKcD/qlk+HhgP0KFDB39CNn5Yn5nL3z9aywXdWjNm0Kleh2OM\n8Yi/Tw09qapzq1qgqqm1EMdo4B1VLavmGJOByQCpqalaC8cLekWlZdwzfSlNI8N4+Nre9qioMUHM\n36qhHiLS/PCEiMSLyJ3H2WYn4DuIbZI7ryqjsWqhOvWvT9ezZvdB/nFdb1rFRnodjjHGQ/4mgnGq\nWvFEj6oeAMYdZ5tFQBcRSRGRCJzCflbllUSkGxAPfONnLOYkfb1xLy98sZmbB3bgwu5tvA7HGOMx\nfxNBqPjUHbhPBEUcawNVLQXuBj4B1gBvqeoqEXlAREb4rDoamK6qVuVTB7IPFfOLt5aR0jKGPw7v\n4XU4xph6wN82go9xGoafd6d/6s47JlWdDcyuNO++StP3+xmDOUmqyh/eW8nevCLe+9FgmkTYKGPG\nGP8TwW9xCv873Ok5wIsBicgEzLuLd/LfFbv5zbDTOD2pmdfhGGPqCX9fKCsHnnW/TAO0fd8h/vzB\nSgaktOCnQzp5HY4xph7x9z2CLsDfgR5A1OH5qtoxQHGZWlRaVs7EGUsICREeG9WXUBtz2Bjjw9/G\n4pdx7gZKgfOB14A3AhWUqV3PzNvE4u3ZPHhVLxKbN/E6HGNMPeNvImiiqp8Doqrb3Abe4YELy9SW\nJdsP8MTnG7iqbztG2kAzxpgq+NtYXOR2Qb1BRO7GeTGsaeDCMrUhv6iUe2cspW1cFH8Z2cvrcIwx\n9ZS/dwT3ANHABOBMYAxwa6CCMrXjgQ9Xs23/IR69oQ/NmthAM8aYqh33jsB9eWyUqv4KyANuC3hU\n5qR9vDKDGWk7uHNoJwZ2tIFmjDHVO+4dgdsR3Dl1EIupJZkHC5k0czmnJzZj4kVdvQ7HGFPP+dtG\nsEREZgFvA/mHZ6rqzIBEZWqsvFz51dvLKCop53EbaKbxUQXrKdbUMn8TQRSwD7jAZ54ClgjqmZe/\n3soXG/byt6t70amVtefXK+VlUJQLRQeh8KDzvSjX/Zzzw7yjlh38YZ2iXAgJg8g4iIo78ntV86Li\nIDIWIpsdOS882hKKqeDvm8XWLtAArM04yMMfr+Wi7m24aUAQDuBTlAsHtkH2Njiw9cjPBdkQEup+\nhTlfcvhzpfkhoT7LqlguvtM+8wGK844u0AvdQr049/jncFQh3wyan+oU5ocL9fLSH/Z5eP/5m49M\nIBynD0cJ9dlns6MTR3gTKC93jnX4S8ucZFZeeuR3LfNZz3edyttUWq5lPj/nkOP/fI/6vfhsU+12\noSCN6K6425XQvn+t79bfN4tfpoq/LFX9ca1HZGqksKSMidOXEhcVzsPXnt44B5opK4GcHU4Bf2Cr\nW8j7fD6078j1I2IhPhkSOkN0C6dg86fQKiuB8sIj1ztiu2oKSC2HiKZHFqqxbaooaOOqL4TDok7+\nSr283ElIRyWjqhKUz53HwXTY484rKTy6QK2yMK6mEA+LPH4hLqHOz8w3MRzr91JSXHUyqfb3We78\nLo+XFBuSFh29SwTAf3w+RwFXA7tqPRpTY//8ZB1rM3J5eWx/Epo20IFmVCFvT9WF/IFtTkGl5T+s\nHxIGzTs4V8zdR0D8qc7n+GTnq0l8cFZ/hIQ4SSUqDqxvQeMHf6uG3vWdFpFpwJcBicicsC82ZPHS\nl1v40Vmncn631l6Hc3yqTuGengY7F8O+jW6Bvx1KC45ct2lbp4A/9Sy3kHcL+uanQlw750rTGHNS\n/L0jqKwL0ABKnMbvQH4xv3p7GZ1bN+X3l3f3OpyqFeU6BX76Itj5vfM9P8tZFtbEqbpp2QW6XOxz\nRX+qc7Ufbn0jGRNo/rYRVG59ysAZo8B4SFX53cwV7M8vZsrY/kSF14Or4/IyyFrnFvppzlX/njVU\n/PkkdIHOF0PSmZDUH1r3gFB769kYL/lbNRQb6EDMiXs7LZ2PV2Xwu8u60bOdR5XBeVlugb/ILfyX\n/PB0TFRzSEqFHiOd74lnOvX2xph6xd87gquB/6lqjjvdHBiqqu8HMjhTva1787n/w1Wc1TGBcefW\n0bAQpUWQscIt9N3CP3ubs0xCoW0v6DMKElOdq/2ETsHZWGtMA+NvG8GfVfW9wxOqmi0ifwaOmQhE\nZBjwBBAKvKiqD1Wxzg3A/Th1B8tU9SY/YwpaJWXlTJyxlLAQ4V839CEkUAPNHNh2ZKGfsRzKip1l\ncYnOVX7/251C/5Q+EBEdmDiMMQHlbyKo6o2MY27rdlb3NHAxkA4sEpFZqrraZ50uwO+Awap6QESs\nAdoP//7fRpbuyObfN/ajXTTYCUYAABUSSURBVG0PNFNaBKs/gIWTncIfnAbddv1g4M+cQj8p1Xli\nxxjTKPibCNJE5FGcgh3gLuD742wzANioqpsBRGQ6MBJY7bPOOOBpVT0AoKp7/A08WC3csp+n/reB\na85I5Mo+tVgY56RD2svw/StwaK/zJM8lD0LKEGvQNaaR8zcR/Bz4EzADpwpnDk4yOJZEYIfPdDow\nsNI6XQFE5Cuc6qP7VfXjyjsSkfHAeIAOHYKw6wRX9qFiJk5fQocW0TxQGwPNqMKWBbDoBVg7G1Do\nOgwGjIOUoc6LScaYRs/fp4bygUkBOn4XYCiQBCwQkdNVNbvS8ScDkwFSU1Mb0fvi/lNVJr27gqy8\nImbeMZimkTV9BQTnuf5l02HhC7B3HTRpAWf/HFJ/7Dy/b4wJKv4+NTQHuP5wAS0i8cB0Vb30GJvt\nBNr7TCe583ylA9+pagmwRUTW4ySGRX7GHzSmLtzOx6sy+MPl3Tk9qYaPimatg0UvwtJpziOe7frB\nVc9Cz2sgPKp2AzbGNBj+Xla29L1K97NhdxHQRURScBLAaKDyE0HvAzcCL4tIS5yqos1+xhQ01mfm\n8sCHqzm3S0t+ck7KiW1cVgrrP3Ku/rfMh9AIp+AfMN55qcsYE/T8TQTlItJBVbcDiEgyx+nST1VL\n3YHuP8Gp/5+iqqtE5AEgTVVnucsuEZHVQBnwa1XdV/1eg09hSRk/n7qE2KiwE3tUNC8LFr/qNAAf\nTIe4JLjwPjjjVohpGdigjTENir+J4A/AlyIyHxDgXNzG22NR1dnA7Erz7vP5rMAv3C9Thb/9dw3r\nMnN55bb+tI49TvWNqtOXz8LJsOo955n/jkPhsoedRuDQk2hXMMY0Wv42Fn8sIqk4hf8SnCqdgmNv\nZU7WJ6syeP3bbYw7N4Whpx2jJq6kAFbOdJ7+2bXE6Yf/zNucl71a2ZjFxphj87ex+HbgHpwG36XA\nIOAbjhy60tSiXdkF/OYdZwD6X1/areqVDmyDtJdg8WtQcABadYPLH4E+o52BT4wxxg/+1hXcA/QH\nvlXV80WkG/B/gQsruJWVKxNnLKWkrJwnb+x39AD06Wmw4BFY/7EzDF+34U7jb/I51rePMeaE+ZsI\nClW1UEQQkUhVXSsipwU0siD29NyNLNyyn39d34eUljFHLlw6FWZNgCbNYcivnCqgZoneBGqMaRT8\nTQTpbo+j7wNzROQAsC1wYQWvtK37efyz9VzVtx3XnOFTwJeXw9y/wRePQMp5cMNrTjIwxpiT5G9j\n8dXux/tFZC7OSKhHdQVhTk7OoRLumb6UpPho/npVrx8GoC8phPfvgFUzod8tcMVj1vePMabWnPDz\nhKo6PxCBBDtV5ffvrSDzYCHv3HE2sVFuQZ+/F6bdCOkL4aK/wOB7rB3AGFOr7MHyemLGoh38d8Vu\nJl3Wjb7t3SqfrHXw5vWQl+lUBfUY6W2QxphGyRJBPbBxTy73f7iKczq3ZPzh0cY2z4MZP4KwSBg7\n27qDMMYEjPUz7LHCkjLunrqEmIgwHj3chcTi1+CNa53BX8Z9bknAGBNQdkfgsYc+WsvajFxeHtuf\n1k0jYM6f4avHodMFcP0rEOXRoPTGmKBhicBDn63O5JWvt/KTc1I4v2NTePtWWDPLGRfgsn9a30DG\nmDphJY1HMnIK+fU7y+jZLo7fnNMcXr0Cdi6GS/4GZ91lTwYZY+qMJQIPlJUr985YSmFJOc9d0oTI\nly91xgke9QZ0v8Lr8IwxQcYSgQeem7+Jbzbv49Xzcmn/3jgIj4bbZjsjhhljTB2zRFDHvt92gEfn\nrOehU9MYsvAJaN0dbpoBzZK8Ds0YE6QsEdShnIISJk5N48Ho6YzO/AC6XALXTbEuo40xnrJEUEdU\nlb+8u5A/FTzEJSFpTrfRl/7dngwyxnjOSqE68uGXixm7/i56hWyDYQ/DoJ95HZIxxgABfrNYRIaJ\nyDoR2Sgik6pYPlZEskRkqft1eyDj8cqONd/R/7Pr6Rq6Gx091ZKAMaZeCdgdgYiEAk8DFwPpwCIR\nmaWqqyutOkNV7w5UHF4rWfsxCTPGkitNyL/5vyR0TvU6JGOMOUIg7wgGABtVdbOqFgPTgeDqPnPh\nC4ROv5HN5W3YcOX7lgSMMfVSIBNBIrDDZzrdnVfZtSKyXETeEZH2Ve1IRMaLSJqIpGVlZQUi1tpV\nXgYf/RZm/4rPy/oyq9+LnHNmH6+jMsaYKnnd++iHQLKq9gbmAK9WtZKqTlbVVFVNbdWqVZ0GeMKK\n8mD6TfDdc7wpw3k84c/84oozvI7KGGOqFcinhnYCvlf4Se68Cqq6z2fyReAfAYwn8A7th9dGopkr\neaX53fxj37l8eFMqUeGhXkdmjDHVCuQdwSKgi4ikiEgEMBqY5buCiJziMzkCWBPAeAKrKM8ZTSxr\nHbN7Pc5fMs7m/hE96Ny6qdeRGWPMMQXsjkBVS0XkbuATIBSYoqqrROQBIE1VZwETRGQEUArsB8YG\nKp6AKi2Gt26BXYvZfMGz3PNRHMN7t+WG1CqbPIwxpl4RVfU6hhOSmpqqaWlpXofxg/IyePd2WDWT\nkuFPcuHcDpSVK7PvOZdmTcK9js4YYwAQke9VtcpHF71uLG7YVOGj38CqmXDxA7xZPITt+w/xj+t6\nWxIwxjQYlghOxry/w6IXYfA9FA/8Oc8v2Ez/5HgGd27pdWTGGOM3SwQ19d3zMP9h6DcGLvoL7y/Z\nye6cQu48v7PXkRljzAmxRFATy992qoS6XQFXPEGZwrPzN9ErMY6hXev5ew7GGFOJJYITtWEOvP8z\nSD4Xrn0JQsP474rdbNmbz11DOyM21rAxpoGxRHAitn8HM26BNj1h9FQIj0JVeWbuRjq1iuHSnm29\njtAYY06YJQJ/Za6CqddDXDu4+V2IigPg8zV7WJuRy51DOxMSYncDxpiGxxKBPw5shdevcQaZ/9H7\n0NRpB1BVnpq7kaT4Jozo287bGI0xpoYsERxP3h547SooLYRb3oPmHSoWfbNpH0t3ZPPT8zoRHmo/\nSmNMw2RDVR5LYQ68cQ3kZcKPZkHr7kcsfmruRlrHRnL9mUkeBWiMMSfPLmOrU1IA026EPWth1OvQ\nvv8RixdvP8DXm/Yx7tyO1ruoMaZBszuCqpSVwjs/hm1fw7UvQueLjlrlmbkbaR4dzk0DO1SxA2OM\naTjsjqCy8nKY9XNYNxsu/yecft1Rq6zZfZDP1uzhtrNTiIm0XGqMadgsEfhShTl/gmVTYejvYcC4\nKld7Zt4mYiJCGXt2ct3GZ4wxAWCJwNdXj8M3T8GA8XDeb6pcZcvefP67fBdjzjqVZtHWw6gxpuGz\nRHDY96/CZ/dDr+tg2MNQTVcRz87bSHhoCLef07Fu4zPGmACxRACwehb8Z6LTKHzVsxBS9Y9lZ3YB\nMxfvZHT/9rSKjazjII0xJjAsEWyeD+/+BBJT4YbXICyi2lVfWLAZgPHndaqr6IwxJuCCOxHsXAzT\nb4KEznDTDIiIqXbVrNwipi3cztX9Ekls3qQOgzTGmMAKaCIQkWEisk5ENorIpGOsd62IqIhUOZ5m\nQOzdAG9eB9EtYMxM5/sxTPlqCyVl5dwx1O4GjDGNS8ASgYiEAk8DlwE9gBtFpEcV68UC9wDfBSqW\no+TsdPoPkhC45X2IO+XYqx8q4fVvtnH56afQsVXTOgrSGGPqRiDvCAYAG1V1s6oWA9OBkVWs91fg\nYaAwgLH84NB+eP1qKDoIY96FhONf4b/6zVbyikq5c6gNQ2mMaXwCmQgSgR0+0+nuvAoicgbQXlX/\ne6wdich4EUkTkbSsrKyaR1SU51QHHdgKN06DU/ocd5P8olKmfLWFC7u1pke7uJof2xhj6inPGotF\nJAR4FPjl8dZV1cmqmqqqqa1a1XBM4NIimDEGdi2F61+B5HP82mzawu1kHyrhrgvsbsAY0zgFMhHs\nBNr7TCe58w6LBXoB80RkKzAImBWwBuP5/4DNc2HEv6Hb5X5tUlhSxuQFmzmrYwJndIgPSFjGGOO1\nQPaYtgjoIiIpOAlgNHDT4YWqmgO0PDwtIvOAX6lqWkCiGXwPtOkBva71e5N3F6ezJ7eIx0b1DUhI\nxhhTHwTsjkBVS4G7gU+ANcBbqrpKRB4QkRGBOm61ouJOKAmUlpXz3PxN9G3fnLM7JQQwMGOM8VZA\n+1BW1dnA7Erz7qtm3aGBjOVEzVq2ix37C7jvip5INf0OGWNMYxDcbxZXo7xceWbeJrq1jeXCbq29\nDscYYwLKEkEVPl2dwcY9edx5fmdCQuxuwBjTuFkiqERVeWruRpITohl++rHfODbGmMbAEkElCzbs\nZeXOg9wxtBOhdjdgjAkClggqefp/GzmlWRRX90vyOhRjjKkTlgh8LNyyn4Vb9zN+SEciwuxHY4wJ\nDlba+Xh67kYSYiIY3b+D16EYY0ydsUTgWpGew/z1Wfzk3BSaRIR6HY4xxtQZSwSup+duJDYqjDGD\nTvU6FGOMqVOWCIANmbl8vCqDsWcnExcV7nU4xhhTpywRAM/O20ST8FBuG5zidSjGGFPngj4RbN93\niA+W7eKmgR1oERPhdTjGGFPngj4RPL9gE6EijB/S0etQjDHGE0GdCDIPFvJ2WjrXpSbRJi7K63CM\nMcYTQZ0IXliwmTJVfjbk+APYG2NMYxW0ieBAfjFvfredEX3a0SEh2utwjDHGM0GbCF7+agsFJWXc\nOdTuBowxwS0oE0FuYQmvfL2VS3u2oUubWK/DMcYYTwVlInjj2+0cLCzl7vO7eB2KMcZ4LqCJQESG\nicg6EdkoIpOqWP4zEVkhIktF5EsR6RHIeAAKS8p46cvNDOnaitOTmgX6cMYYU+8FLBGISCjwNHAZ\n0AO4sYqCfqqqnq6qfYF/AI8GKp7Dpi/czt68Yu6ytgFjjAECe0cwANioqptVtRiYDoz0XUFVD/pM\nxgAawHgoLi1n8oLN9E+OZ2DHhEAeyhhjGoxAJoJEYIfPdLo77wgicpeIbMK5I5hQ1Y5EZLyIpIlI\nWlZWVo0Den/JTnblFHLX+Z1rvA9jjGlsPG8sVtWnVbUT8Fvgj9WsM1lVU1U1tVWrVjU6Tlm58uz8\nTfRKjOO8rjXbhzHGNEaBTAQ7gfY+00nuvOpMB64KVDCzV+xmy9587hraGREblN4YYw4LZCJYBHQR\nkRQRiQBGA7N8VxAR3+c3hwMbAhVMTGQoF/dow6U92wbqEMYY0yCFBWrHqloqIncDnwChwBRVXSUi\nDwBpqjoLuFtELgJKgAPArYGK54JubbigW5tA7d4YYxqsgCUCAFWdDcyuNO8+n8/3BPL4xhhjjs/z\nxmJjjDHeskRgjDFBzhKBMcYEOUsExhgT5CwRGGNMkLNEYIwxQc4SgTHGBDlRDWiHn7VORLKAbTXc\nvCWwtxbD8ZKdS/3TWM4D7Fzqq5M5l1NVtcqO1hpcIjgZIpKmqqlex1Eb7Fzqn8ZyHmDnUl8F6lys\nasgYY4KcJQJjjAlywZYIJnsdQC2yc6l/Gst5gJ1LfRWQcwmqNgJjjDFHC7Y7AmOMMZVYIjDGmCAX\nNIlARIaJyDoR2Sgik7yOp6ZEpL2IzBWR1SKySkQa9JgOIhIqIktE5D9ex3IyRKS5iLwjImtFZI2I\nnOV1TDUlIve6f1srRWSaiER5HZO/RGSKiOwRkZU+81qIyBwR2eB+j/cyRn9Ucx7/dP++lovIeyLS\nvLaOFxSJQERCgaeBy4AewI0i0sPbqGqsFPilqvYABgF3NeBzAbgHWON1ELXgCeBjVe0G9KGBnpOI\nJAITgFRV7YUzuuBob6M6Ia8AwyrNmwR8rqpdgM/d6fruFY4+jzlAL1XtDawHfldbBwuKRAAMADaq\n6mZVLQamAyM9jqlGVHW3qi52P+fiFDiJ3kZVMyKShDNW9Ytex3IyRKQZMAR4CUBVi1U129uoTkoY\n0EREwoBoYJfH8fhNVRcA+yvNHgm86n5+FbiqToOqgarOQ1U/VdVSd/JbIKm2jhcsiSAR2OEznU4D\nLTx9iUgy0A/4zttIauxx4DdAudeBnKQUIAt42a3melFEYrwOqiZUdSfwCLAd2A3kqOqn3kZ10tqo\n6m73cwbQGAYv/zHwUW3tLFgSQaMjIk2Bd4GJqnrQ63hOlIhcAexR1e+9jqUWhAFnAM+qaj8gn4ZR\n/XAUt/58JE5yawfEiMgYb6OqPeo8L9+gn5kXkT/gVBG/WVv7DJZEsBNo7zOd5M5rkEQkHCcJvKmq\nM72Op4YGAyNEZCtOVd0FIvKGtyHVWDqQrqqH78zewUkMDdFFwBZVzVLVEmAmcLbHMZ2sTBE5BcD9\nvsfjeGpMRMYCVwA3ay2+BBYsiWAR0EVEUkQkAqfxa5bHMdWIiAhOXfQaVX3U63hqSlV/p6pJqpqM\n8/v4n6o2yCtPVc0AdojIae6sC4HVHoZ0MrYDg0Qk2v1bu5AG2vDtYxZwq/v5VuADD2OpMREZhlOV\nOkJVD9XmvoMiEbgNLHcDn+D8Ub+lqqu8jarGBgO34FxBL3W/Lvc6KMPPgTdFZDnQF/g/j+OpEfeu\n5h1gMbACp4xoMF00iMg04BvgNBFJF5GfAA8BF4vIBpw7noe8jNEf1ZzHU0AsMMf9v3+u1o5nXUwY\nY0xwC4o7AmOMMdWzRGCMMUHOEoExxgQ5SwTGGBPkLBEYY0yQs0RgTB0SkaENvadV0/hYIjDGmCBn\nicCYKojIGBFZ6L6487w7bkKeiDzm9tX/uYi0ctftKyLf+vQTH+/O7ywin4nIMhFZLCKd3N039Rm7\n4E33DV5jPGOJwJhKRKQ7MAoYrKp9gTLgZiAGSFPVnsB84M/uJq8Bv3X7iV/hM/9N4GlV7YPTX8/h\nHjD7ARNxxsboiPO2uDGeCfM6AGPqoQuBM4FF7sV6E5yOysqBGe46bwAz3bEImqvqfHf+q8DbIhIL\nJKrqewCqWgjg7m+hqqa700uBZODLwJ+WMVWzRGDM0QR4VVWPGAFKRP5Uab2a9s9S5PO5DPs/NB6z\nqiFjjvY5cJ2ItIaKMW9Pxfl/uc5d5ybgS1XNAQ6IyLnu/FuA+e7ocekicpW7j0gRia7TszDGT3Yl\nYkwlqrpaRP4IfCoiIUAJcBfOgDMD3GV7cNoRwOna+Dm3oN8M3ObOvwV4XkQecPdxfR2ehjF+s95H\njfGTiOSpalOv4zCmtlnVkDHGBDm7IzDGmCBndwTGGBPkLBEYY0yQs0RgjDFBzhKBMcYEOUsExhgT\n5P4fRYymSOgaikYAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A2j7f2BIvTVW",
        "outputId": "2096880f-f022-4a36-d21a-bb4ad041d5fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FctR448gLi7d"
      },
      "source": [
        "As it appears we were able to reach 64% accuracy on the validation set. The accuracy on the training set on the other hand was at 100% which is a clear sign that our model overfitted on the training dataset and was not able to generalize well, thus firing the early callback and stopping the training process at 15 epochs. Some possible reasons of that matter could be the fact that our model was not able to catch the true semantic meaning of the tweets or our dataset was just too small making our model incapable of learning."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ddq1lKreBpRf",
        "outputId": "c1dd91f7-5003-402d-8a5d-270771705de6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "score = model.evaluate(test_X, test_Y,\n",
        "                       batch_size=batch_size, verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2536/2536 [==============================] - 0s 20us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E-PpCZFnGk1s",
        "outputId": "9424ffbd-e496-47bd-bf38-01df0a646e24",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "score[1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6328864357072849"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S0j_cVHCHI0W"
      },
      "source": [
        "After evaluating the keras model n the test dataset the accuracy score is around 63%."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wg8vrsE_IIy9"
      },
      "source": [
        "score_bin = score_bin.append(pd.Series([14, 'Neural Network', score[1]], index=score_bin.columns), ignore_index=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OaqShq3PJko7",
        "outputId": "d9c8e746-772d-4c7c-839c-105dda6e63c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        }
      },
      "source": [
        "plt.bar(list(score_bin.iloc[:, 1]), list(score_bin.iloc[:, 2]))\n",
        "plt.xticks(rotation = 90)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14],\n",
              " <a list of 15 Text xticklabel objects>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAFMCAYAAADbSkeTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AnaP4Q8_L2vo"
      },
      "source": [
        "As it appears the Neural Network model was able to achive greater accuracy on the test set, following the SVM model after grid search, the Naive Bayes after grid search and the logistic regression after grid search."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qJ7T91feNmGD"
      },
      "source": [
        "## Further Research"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ou_nUUxrMT_X"
      },
      "source": [
        "In order to achieve bette results a possible next step would be to download GLOVE embedings and retrain them to better suit the data. I more complex Neural network could be fitted using Convolutional Layers and LSTM Layers to better catch the semantic meaning of the tweets. Also since neural networks require a lot of data to be trained since they have much more parameters that classic machine learning models, an oversampling technique could be used in the training data only (SMOTE package). Apart from that ensembling between models that perfom their best on different classes may produce a model that could generalize better and achieve a more accurate classification."
      ]
    }
  ]
}